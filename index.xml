<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>zero.xu blog</title>
    <link>https://xujianhai.fun/</link>
    <description>Recent content on zero.xu blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 10 Jul 2020 15:22:42 +0800</lastBuildDate>
    
	<atom:link href="https://xujianhai.fun/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Message_batch</title>
      <link>https://xujianhai.fun/posts/message_batch/</link>
      <pubDate>Fri, 10 Jul 2020 15:22:42 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/message_batch/</guid>
      <description>序 最近小伙伴聊到 batch消息 在ack的处理方式, 是一个个ack? 还是批量ack? 如果是多个消息存储成1个, 那么 offset 是怎么管理的呢? 消费的时候, ack掉一个就多个消息都被ack了? 那么因为分成了多个消息消费, 会不会导致重复ack?
根据之前写rocketm-client-go的经验, client 传递给broker的消息确实是 batch后的 一条消息, 可是后面的路子就不是很清楚了. 因此深入研究下.
RocketMQ 应用实战  首先, 重新验证下 对批量消息的理解, 运行下 org.apache.rocketmq.example.batch.SimpleBatchProducer 和 org.apache.rocketmq.example.simple.PushConsumer 的例子, SimpleBatchProducer 发送批量消息后, 可以发现 PushConsumer 消费的时候, 其实是一条条消费的:
message: Hello world 0 0A5DE93A000018B4AAC231F9BC180000 3 message: Hello world 2 0A5DE93A000018B4AAC231F9BC180002 5 message: Hello world 1 0A5DE93A000018B4AAC231F9BC180001 4 这样就郁闷了, 发送的时候是批量成一条消息发送的(见下文), 那么什么时候解成一条条消息的呢? 而且打印的时候, 我特意打印了每个消息的 messageId 和 queueOffset, 可以发现这些消息的 queueOffset 确实不一样, 也就是说消息确实不一样.
 client  首先看下 client 是怎么传递消息的.</description>
    </item>
    
    <item>
      <title>Bigtable</title>
      <link>https://xujianhai.fun/posts/bigtable/</link>
      <pubDate>Wed, 08 Jul 2020 21:26:27 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/bigtable/</guid>
      <description>preface 看完mit的课程, 意犹未尽, 因为google素有三驾马车之称的论文中, GFS 和 spanner 已经看过, 但是bigtable却没有深入了解过, 虽然基于 bigtable 论文实现的 hbase已经非常知名, 顺便结合之前的 hbase 学习的经验.
design 在数据模型上, bigtable在论文中是宣称是 sparse, distributed, persistent multidimensional sorted map, 存储的kv结构是 (row:string, column:string, time:int64) → string, 通过key 中包含的time 实现了多版本的机制(会配置只保持最近n个版本, 或者老版本存活多少天), 通过 row 将同一个对象的多个属性(column)进行聚合, column 的分散设计能够高效的并发. bigtable 通过rowkey的字节序排序维护数据, 并且每个table的数据是动态partition的(分布式&amp;amp;负载均衡), partition的row range就是 tablet. 为了更好的管理column, 采用了 column family/cf 的设计, 类似于 group的概念, 一个 cf 下的数据通常是一起压缩的 并且数据类型相同, 访问控制配置也一样. 由于cf的设计, 一个 column key name就会变成: family:qualifier, qualifier 可以理解为 key, 在举例的场景中, web page 存储就分成了 cf: anchor, qualifer 是被引用的站点, 比如 google.</description>
    </item>
    
    <item>
      <title>Broken_pipe</title>
      <link>https://xujianhai.fun/posts/broken_pipe/</link>
      <pubDate>Tue, 23 Jun 2020 18:33:37 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/broken_pipe/</guid>
      <description>Preface 最近使用sarama(kafka go client) 发现大量的报错: write: broken pipe, 并且还触发了我们的日志报警, 感到奇怪, 研究了一下
报错类型 除了 broken pipe, 还有 reset by peer 和 EOF 两种报错. 根据查阅资料, 最终整理如下:
 Broken pipe: 是 第二次向 closed tcp pipe(收到了rst报文) 写入数据导致的报错 reset by peer: 是 在写入 closed tcp pipe(收到了rst报文) 之后读取操作 报错 io.EOF: 如果对端的写端关闭连接，读端继续读，报错EOF  这里 reset by peer 和 io.EOF 存在一定的雷同, 下面针对这三种情况进行测试:
program 在 broken pipe 和 EOF 的测试中, 使用的server 和 client 代码是一个, 如下:
package main import ( &amp;#34;log&amp;#34; &amp;#34;net&amp;#34; &amp;#34;time&amp;#34; &amp;#34;unsafe&amp;#34; ) func main() { doClient() } func doClient() { d := &amp;amp;net.</description>
    </item>
    
    <item>
      <title>Bytable</title>
      <link>https://xujianhai.fun/posts/bytable/</link>
      <pubDate>Mon, 22 Jun 2020 20:34:35 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/bytable/</guid>
      <description>Preface 最近头条发布了关于 Bytable 的文章: https://juejin.im/post/5ee376fe518825434566d1de , 特地学习下
Bytable 有三种角色: master(控制平面) 、placement driver(Placement Driver) 、tabletServer(TabletServer)
feature: 拆分了 tablet 的 raft 的membership 和 Leader Election 到master, 降低心跳的开销 (tablet server 只需要和master进行通信, 不需要为每个 tablet group进行 tablet server 之间的心跳, 后者随着tablet的增长而增长), leader election 放在master 可以自定义更多的策略
自研了一套WAL 存储引擎 避免同时写入 复制日志和引擎日志 导致的 HDD 盘磁头摇摆, 进而写入性能降低的问题, 按照文章的说法: 不进行 Compaction 时也可以打满 HDD 盘的写入带宽
问题:
 Split 和 Merge 使用硬链 降低不可用时间, 但是用了硬链, 文件还是一个, 应该还是存在将分裂的tablet 传给其他 tabletServer, 除非分裂还在本地的taletServer  大概能够明白, 使用硬链避免在传输sst文件的时候，文件被compaction流程删除. (需要确认下)</description>
    </item>
    
    <item>
      <title>Redis_debug</title>
      <link>https://xujianhai.fun/posts/redis_debug/</link>
      <pubDate>Sat, 13 Jun 2020 00:06:10 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/redis_debug/</guid>
      <description>Preface 最近小伙伴讨论到了如何调试c/cpp 应用, 其中讲到了 compile db 这个组件, 不是很了解, 这里学习下
redis 先用redis调试, 其中主要参考了 https://my.oschina.net/icebergxty/blog/4309023, 整个过程都成功了, 但是需要注意的是, 在创建调试的配置的时候, 选择的是二进制的应用, 而不是 server.c, 虽然选择的是二进制, 但是调试还是可以的, 打的断点可以执行到.
使用 compile db 调试, 避免了 在每个模块添加 CMakeList.txt 的操作, 快速很多
参考的blog是中文的, 可以参考英文官方文档: https://www.jetbrains.com/help/clion/custom-build-targets.html#.
mysql cmake
-DCMAKE_INSTALL_PREFIX=/Users/jianhaixu/secrect/opensource/mysql-server/debug
-DMYSQL_DATADIR=/Users/jianhaixu/secrect/opensource/mysql-server/debug/data
-DSYSCONFDIR=/Users/jianhaixu/secrect/opensource/mysql-server/debug
-DMYSQL_UNIX_ADDR=/Users/jianhaixu/secrect/opensource/mysql-server/debug/data/mysql.sock
-DWITH_DEBUG=1 -DFORCE_INSOURCE_BUILD=1
-DDOWNLOAD_BOOST=1
-DWITH_BOOST=/Users/jianhaixu/Downloads/boost_1_70_0
make -j 4
make install -j 4
bin/mysqld &amp;ndash;initialize-insecure &amp;ndash;user=root &amp;ndash;datadir=/Users/jianhaixu/secrect/opensource/mysql-server/debug/data
bin/mysqld &amp;ndash;defaults-file=/Users/jianhaixu/secrect/opensource/mysql-server/debug/etc/my.cnf</description>
    </item>
    
    <item>
      <title>Python_tool</title>
      <link>https://xujianhai.fun/posts/python_tool/</link>
      <pubDate>Mon, 08 Jun 2020 13:11:08 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/python_tool/</guid>
      <description>火焰图 pyframe https://github.com/uber/pyflame https://pyflame.readthedocs.io/en/latest/
不侵入代码, 支持诊断多线程. 支持 火焰图、线程应用、stack trace. 但是不支持web导出, 需要自己做
vprof https://github.com/nvdv/vprof
支持cpu火焰图、内存火焰图，代码执行时间、web导出, 看上去很丰富
profile_online https://github.com/rfyiamcool/profiler_online
比较简单, 只支持火焰图, 支持web导出
py-spy (目前用这个) https://github.com/benfred/py-spy
打印堆栈、火焰图、top</description>
    </item>
    
    <item>
      <title>Mit_6</title>
      <link>https://xujianhai.fun/posts/mit_6.824/</link>
      <pubDate>Sat, 06 Jun 2020 10:23:10 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/mit_6.824/</guid>
      <description>序 记录学习 mit 6.824 课程的经历
MapReduce 1 目标: 将任务拆解成map 和 reduce 两个阶段, 进行 大规模的数据处理, 比如 页面爬取、词频统计
模型 如上图, map/reduce 架构会将用户输入切成若干份数据输入(map的个数), 由map进行处理, 按照论文的说法, map读取文件是本地读取操作, map计算后得到的结果, 会按照 hash到若干份(reduce个数)本地文件存储, 并将存储位置上报给 master, master启动reduce worker, reduce worker会远程获取 每个map机器上的文件, 本地计算后输出到 gfs(分布式文件存储)上. 为了更好的性能和效果, 在map输出后以及reduce输入前, 会有一个combiner任务, 对map的结果进行预处理, 减少网络传输, 但是和reduce不同, combiner 的输出结果是存储在磁盘上的.
分布式场景下, 容易出现一些坏的机器导致map/reduce 执行慢, 对此, map/reduce 架构会重新执行任务. 对于执行完宕机的场景, map会触发重新执行(结果存放在本地), reduce 不需要重新执行(结果存放在gfs)
map/reduce的场景中, 需要处理 热点倾斜的问题, 因为会出现大量数据集中在一台reduce机器上, 对于这种问题, 需要自定义良好的 partition 函数, 将数据尽可能的平均打散
hadoop 架构
将论文中 partition/combiner 的抽象成 shuffle, 进行分区、排序、分割, 将属于同一划分（分区）的输出合并在一起并写在磁盘上，最终得到一个分区有序的文件.</description>
    </item>
    
    <item>
      <title>Kafka_group_coordinator</title>
      <link>https://xujianhai.fun/posts/kafka_group_coordinator/</link>
      <pubDate>Sat, 30 May 2020 21:27:58 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/kafka_group_coordinator/</guid>
      <description>preface 因为工作内容涉及 kafka, 今天梳理下 kafka group coordinator
coordinator group coordinator 是计算出来的, 是hash groupId计算出来取模元数据的partition个数, 代码如 Utils.abs(groupId.hashCode) % groupMetadataTopicPartitionCount, 然后取这个partition的leader broker 就是这个group的coordinator. 具体在findCoordinator的实现中.
coordinator 的主要任务是: 1. consumer rebalance 2. offset 管理
coordinator rebalance 模块比较简单, 之前客户端开发的时候总结过一波. 如下:
客户端找到一个Node -&amp;gt; find coordinator protocol -&amp;gt; onJoinPrepare(子类) -&amp;gt; join group protocol -&amp;gt; sync group protocol(onJoinLeader 包含了任务分配的结果/follower 空的assignment) -&amp;gt; enable heartbeat -&amp;gt;onJoinComplete(子类处理分配结果). 心跳线程处理 coordinator的网络连接. leader 是 coordinator 选举的. 在group coordinator的kafka server端, 主要处理 join group protocol 和 sync group protocol.</description>
    </item>
    
    <item>
      <title>Linux_iouring</title>
      <link>https://xujianhai.fun/posts/linux_iouring/</link>
      <pubDate>Tue, 26 May 2020 22:32:44 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/linux_iouring/</guid>
      <description>Preface 最近内部经常讨论 io_uring, 这块不是很了解, 特别记录下
回顾io linux io 模型中主要区分四种类型区分: 同步io 非同步io 和 阻塞io 非阻塞io, 通过不同的组合, 有不同的模型. 如下:
 同步io + 阻塞io: 用户进程会被阻塞在 recvfrom. 同步io + 非阻塞io: recvfrom 会返回 错误表示数据还没有到来, 不会阻塞. O_NONBLOCK 参数 同步io + 阻塞io: io多路复用: select/poll/epoll, 虽然读写不会阻塞在recvfrom, 但是会阻塞在select调用. 信号驱动: 接收到信号之后需要自己操作 异步io: 内核操作完通知. 操作系统提供了 libaio  有人还将 异步io + epoll 进行了实现: http://m.blog.chinaunix.net/uid-16979052-id-3840266.html
io_uring   定位: 更高 IOPS 的 async syscall api. (io层的异步api, 主打高性能)
  特点&amp;amp;主要概念
 基于ringbuffer 的设计, 提交队列和完成队列只存储索引, SQEs(submission queue entries) 存储请求, 这样提交的请求可以内存不连续 用户态和系统态 通过 mmap 共享 提交队列 和 完成队列, 减少地址映射开销 在poll模式下, IO提交和收割 可以由 kernel 完成, 不需要系统调用, 系统会启动一个 SQ Poll 的内核线程不断poll (没有请求会睡眠), 处理 sq 和 cq 非poll模式下, io_uring_enter 会阻塞, 完成 SQ Poll 线程的任务 提供了polling和非polling两种模式, 和底层实现有关, 非polling性能比 libaio 提升不了多少, polling 模式和 SPDK 非常接近.</description>
    </item>
    
    <item>
      <title>Kafka_controller</title>
      <link>https://xujianhai.fun/posts/kafka_controller/</link>
      <pubDate>Tue, 26 May 2020 11:45:58 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/kafka_controller/</guid>
      <description>Preface kafka controller 是 kafka 设计中重要的一环, 负责 kafka 集群状态 、topic 元数据的缓存和管理(topic、replica的管理), 下面分成两部分分析 kafka controller. 一部分是 kafka controller 的redesign 设计, 第二部分是从源代码分析和思考
Redesign 网上关于 redesign(https://docs.google.com/document/d/1rLDmzDOGQQeSiMANP0rC2RYp_L7nUGHzFD9MQISgXYM/edit#heading=h.pxfjarumuhko) 翻译的版本很多, 但是在看这个内容之前, 我们需要思考几个问题: 1. 为什么要redesign, 存在什么问题 2. 如何解决这些问题.
从文章内容上来看, 主要存在以下问题:
 每个partition的zk写入是同步, 并发度不够(比如broker宕机导致的 partition leader重新选举、replica摘除) controller-broker 的请求也是每个partition 顺序的 (StopReplicaRequests LeaderAndIsrRequest UpdateMetadataRequest 这些并发量很大的请求, broker宕机的时候触发) 并发管理复杂 (controller-broker channel、zk、kafkaApi 都会操作) controller 代码组织混乱 (replicaStateMachine 和 topicStateMachine 的状态边界分的不是很清晰, 需要一些状态同步) 控制面和数据面没有分离, 控制面的命令不能及时下达, 会导致什么问题呢? (新选举的leader无法及时通知正在忙于处理用户数据的旧的leader, ack=1 和0 的会导致数据丢失) controller-broker 的请求 没有 broker generation, 会导致什么问题呢? (broker收到之前的controller过期的请求) zkClinet 没有状态管理 导致了什么问题?</description>
    </item>
    
  </channel>
</rss>