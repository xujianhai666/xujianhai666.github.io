<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>zero.xu blog</title>
    <link>https://xujianhai.fun/</link>
    <description>Recent content on zero.xu blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 20 Sep 2020 10:00:09 +0800</lastBuildDate>
    
	<atom:link href="https://xujianhai.fun/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Golang_generic</title>
      <link>https://xujianhai.fun/posts/golang_generic/</link>
      <pubDate>Sun, 20 Sep 2020 10:00:09 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/golang_generic/</guid>
      <description>preface 前一段时间golang的泛型再次被提及, 看了相关的proposal之后, 一直没空写, 最近终于得空, 写一波
特点 泛型 基于 type parameter 实现的, type parameter 通常用 [] 圈起来, 如下使用:
func F[T any] (p T) { .... } // T 就是 F 的 type parameter type M[T any] []T // type parameter list 的定义 func F[T Contraint](p T) { .... } // 具有约束的泛型 与之相对的是, 常规的参数是 non-type parameter, 两者最显著的区别就是 [].
除了 type parameter, 频繁的词是 type argument, 是运行泛型代码的时候的入参, 会替换掉 type parameter.
约束可以理解成 对 泛型的行为定义, 但是相比于java, 缺乏了 extend 和 super, 通常用 interface 约束泛型, 比如:</description>
    </item>
    
    <item>
      <title>Network_grpc</title>
      <link>https://xujianhai.fun/posts/network_grpc/</link>
      <pubDate>Sat, 19 Sep 2020 13:11:35 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/network_grpc/</guid>
      <description>准备  client  package main import ( &amp;quot;context&amp;quot; &amp;quot;log&amp;quot; &amp;quot;time&amp;quot; &amp;quot;google.golang.org/grpc&amp;quot; pb &amp;quot;google.golang.org/grpc/examples/helloworld/helloworld&amp;quot; ) const ( address = &amp;quot;localhost:50051&amp;quot; defaultName = &amp;quot;world&amp;quot; ) func main() { // Set up a connection to the server. ctx, cancel := context.WithTimeout(context.Background(), time.Second*3) defer cancel() conn, err := grpc.DialContext(ctx, address, grpc.WithInsecure(), grpc.WithBlock()) if err != nil { log.Fatalf(&amp;quot;did not connect: %v&amp;quot;, err) } defer conn.Close() c := pb.NewGreeterClient(conn) // Contact the server and print out its response.</description>
    </item>
    
    <item>
      <title>Select_chan</title>
      <link>https://xujianhai.fun/posts/select_chan/</link>
      <pubDate>Sun, 13 Sep 2020 11:40:15 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/select_chan/</guid>
      <description>最近小伙伴问了一个有趣的问题, 如果 for-select 监听多个chan, 其中一个是 eventCh, 一个是 closeCh, event 每隔一段时间会有通知, 但是因为 chan blocking 的特性, 每次 slelect 的时候 closeCh 都会将goroutine 添加到 chan 的 sendq, 那么 sendq 的双链 岂不是爆炸？
直观上大家可定认为 不会发生, 会给出一些 猜测的解决方案, 但是到底会发生什么呢? 先写下如下 demo
package main func main() { doCh := make(chan struct{}) dataCh := make(chan struct{}) select { case &amp;lt;-doCh: case &amp;lt;-dataCh: } } 为了方便反汇编, 执行编译: go build -gcflags &#39;-l&#39; -o main main.go
执行反汇编: go tool objdump -s &amp;quot;main&amp;quot; main</description>
    </item>
    
    <item>
      <title>Google_article</title>
      <link>https://xujianhai.fun/posts/google_article/</link>
      <pubDate>Tue, 21 Jul 2020 23:06:09 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/google_article/</guid>
      <description>序 读论文的路上继续. 这里主要围绕 spanner sql 、megaStore、F1、dremel 相关的论文.
spanner sql 1 在之前spanner kv的基础上, 主要介绍了sql的实现(从kv-&amp;gt;rdbms), 不同于其他sql+存储松耦合的实现方式(两套系统), spanner 采取了内部紧耦合的策略. 除了sql, 还提及了一个新的数据存储格式: Ressi, 和 SSTable 不同的是, block之间是面向 row的, 但是block内部存储却是面向 列的, 这样既保留了 rowkey 的有序性, 还让单个column的读取更加高效. 除此之外, 还支持冷热数据(老版本数据被放在inactive files) 以及 大value另外存储(避免不必要的读取), Ressi 的底层数据结构是 vector(能够更好的压缩).
sql的研究方面, 介绍了 QUERY DISTRIBUTION （Distributed query compilation 、Distributed Execution、 Distributed joins、Query distribution APIs), QUERY RANGE EXTRACTION(Compile-time rewriting、Filter tree), QUERY RESTARTS(用户体验上的提升, ), 除此之外, 还使用了公司统一的SQL Diaect, 重点介绍了测试. (没有太深的经验, 勿喷)
ps: 建议重试相关工作的时候在读一遍, 没看太懂(不是很想话时间立即学习&amp;hellip;)
可以参考: https://zhuanlan.zhihu.com/p/27544985 学习下</description>
    </item>
    
    <item>
      <title>Paxos</title>
      <link>https://xujianhai.fun/posts/paxos/</link>
      <pubDate>Sun, 12 Jul 2020 21:18:49 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/paxos/</guid>
      <description>preface 在分布式系统中, 共识算法是基层能力, 分布式锁、名字服务、服务注册&amp;amp;发现 都依赖分布式共识算法. 分布式共识的本质是多个server就value达成一致. 目前最流程的是raft, 早期流行过paxos, 讨论paxos的时候需要了解 basic paxos 和 multi paxos. paxos/basic paxos 讨论的是多个副本如何就一个value达成一致, multi paxos 是对一系列value达成一致(一般会提出master+lease+epoch的策略). 下面针对paxos深入学习
ps: 严格意义上说, zab 不是paxos, 但是接近, ZAB是为了构建高可用的分布式主备系统, paxos则是用于构建分布式的一致性状态机. 因此这里放在一起讨论
essay  paxos made simple 1  入门级读物, 讨论了如何确定一个value: propose + chosen + learn (basic paxos). 提出了paxos中的三个角色: proposer、acceptor、learner. value 被choose的定义是 足够多的acceptor 接受value, 足够多 的定义是基于 quorum协议的. 但是acceptor的accept的行为, 在论文中讨论了几个必要条件:
 P1. An acceptor must accept the first proposal that it receives P1a. An acceptor can accept a proposal numbered n iff it has not responded to a prepare request having a number greater than n.</description>
    </item>
    
    <item>
      <title>Message_batch</title>
      <link>https://xujianhai.fun/posts/message_batch/</link>
      <pubDate>Fri, 10 Jul 2020 15:22:42 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/message_batch/</guid>
      <description>序 最近小伙伴聊到 batch消息 在ack的处理方式, 是一个个ack? 还是批量ack? 如果是多个消息存储成1个, 那么 offset 是怎么管理的呢? 消费的时候, ack掉一个就多个消息都被ack了? 那么因为分成了多个消息消费, 会不会导致重复ack?
根据之前写rocketm-client-go的经验, client 传递给broker的消息确实是 batch后的 一条消息, 可是后面的路子就不是很清楚了. 因此深入研究下.
RocketMQ 应用实战  首先, 重新验证下 对批量消息的理解, 运行下 org.apache.rocketmq.example.batch.SimpleBatchProducer 和 org.apache.rocketmq.example.simple.PushConsumer 的例子, SimpleBatchProducer 发送批量消息后, 可以发现 PushConsumer 消费的时候, 其实是一条条消费的:
message: Hello world 0 0A5DE93A000018B4AAC231F9BC180000 3 message: Hello world 2 0A5DE93A000018B4AAC231F9BC180002 5 message: Hello world 1 0A5DE93A000018B4AAC231F9BC180001 4 这样就郁闷了, 发送的时候是批量成一条消息发送的(见下文), 那么什么时候解成一条条消息的呢? 而且打印的时候, 我特意打印了每个消息的 messageId 和 queueOffset, 可以发现这些消息的 queueOffset 确实不一样, 也就是说消息确实不一样.
 client  首先看下 client 是怎么传递消息的.</description>
    </item>
    
    <item>
      <title>Bigtable</title>
      <link>https://xujianhai.fun/posts/bigtable/</link>
      <pubDate>Wed, 08 Jul 2020 21:26:27 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/bigtable/</guid>
      <description>preface 看完mit的课程, 意犹未尽, 因为google素有三驾马车之称的论文中, GFS 和 spanner 已经看过, 但是bigtable却没有深入了解过, 虽然基于 bigtable 论文实现的 hbase已经非常知名, 顺便结合之前的 hbase 学习的经验.
design 在数据模型上, bigtable在论文中是宣称是 sparse, distributed, persistent multidimensional sorted map, 存储的kv结构是 (row:string, column:string, time:int64) → string, 通过key 中包含的time 实现了多版本的机制(会配置只保持最近n个版本, 或者老版本存活多少天), 通过 row 将同一个对象的多个属性(column)进行聚合, column 的分散设计能够高效的并发. bigtable 通过rowkey的字节序排序维护数据, 并且每个table的数据是动态partition的(分布式&amp;amp;负载均衡), partition的row range就是 tablet. 为了更好的管理column, 采用了 column family/cf 的设计, 类似于 group的概念, 一个 cf 下的数据通常是一起压缩的 并且数据类型相同, 访问控制配置也一样. 由于cf的设计, 一个 column key name就会变成: family:qualifier, qualifier 可以理解为 key, 在举例的场景中, web page 存储就分成了 cf: anchor, qualifer 是被引用的站点, 比如 google.</description>
    </item>
    
    <item>
      <title>Broken_pipe</title>
      <link>https://xujianhai.fun/posts/broken_pipe/</link>
      <pubDate>Tue, 23 Jun 2020 18:33:37 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/broken_pipe/</guid>
      <description>Preface 最近使用sarama(kafka go client) 发现大量的报错: write: broken pipe, 并且还触发了我们的日志报警, 感到奇怪, 研究了一下
报错类型 除了 broken pipe, 还有 reset by peer 和 EOF 两种报错. 根据查阅资料, 最终整理如下:
 Broken pipe: 是 第二次向 closed tcp pipe(收到了rst报文) 写入数据导致的报错 reset by peer: 是 在写入 closed tcp pipe(收到了rst报文) 之后读取操作 报错 io.EOF: 如果对端的写端关闭连接，读端继续读，报错EOF  这里 reset by peer 和 io.EOF 存在一定的雷同, 下面针对这三种情况进行测试:
program 在 broken pipe 和 EOF 的测试中, 使用的server 和 client 代码是一个, 如下:
package main import ( &amp;#34;log&amp;#34; &amp;#34;net&amp;#34; &amp;#34;time&amp;#34; &amp;#34;unsafe&amp;#34; ) func main() { doClient() } func doClient() { d := &amp;amp;net.</description>
    </item>
    
    <item>
      <title>Bytable</title>
      <link>https://xujianhai.fun/posts/bytable/</link>
      <pubDate>Mon, 22 Jun 2020 20:34:35 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/bytable/</guid>
      <description>Preface 最近头条发布了关于 Bytable 的文章: https://juejin.im/post/5ee376fe518825434566d1de , 特地学习下
Bytable 有三种角色: master(控制平面) 、placement driver(Placement Driver) 、tabletServer(TabletServer)
feature: 拆分了 tablet 的 raft 的membership 和 Leader Election 到master, 降低心跳的开销 (tablet server 只需要和master进行通信, 不需要为每个 tablet group进行 tablet server 之间的心跳, 后者随着tablet的增长而增长), leader election 放在master 可以自定义更多的策略
自研了一套WAL 存储引擎 避免同时写入 复制日志和引擎日志 导致的 HDD 盘磁头摇摆, 进而写入性能降低的问题, 按照文章的说法: 不进行 Compaction 时也可以打满 HDD 盘的写入带宽
问题:
 Split 和 Merge 使用硬链 降低不可用时间, 但是用了硬链, 文件还是一个, 应该还是存在将分裂的tablet 传给其他 tabletServer, 除非分裂还在本地的taletServer  大概能够明白, 使用硬链避免在传输sst文件的时候，文件被compaction流程删除. (需要确认下)</description>
    </item>
    
    <item>
      <title>Redis_debug</title>
      <link>https://xujianhai.fun/posts/redis_debug/</link>
      <pubDate>Sat, 13 Jun 2020 00:06:10 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/redis_debug/</guid>
      <description>Preface 最近小伙伴讨论到了如何调试c/cpp 应用, 其中讲到了 compile db 这个组件, 不是很了解, 这里学习下
redis 先用redis调试, 其中主要参考了 https://my.oschina.net/icebergxty/blog/4309023, 整个过程都成功了, 但是需要注意的是, 在创建调试的配置的时候, 选择的是二进制的应用, 而不是 server.c, 虽然选择的是二进制, 但是调试还是可以的, 打的断点可以执行到.
使用 compile db 调试, 避免了 在每个模块添加 CMakeList.txt 的操作, 快速很多
参考的blog是中文的, 可以参考英文官方文档: https://www.jetbrains.com/help/clion/custom-build-targets.html#.
mysql cmake
-DCMAKE_INSTALL_PREFIX=/Users/jianhaixu/secrect/opensource/mysql-server/debug
-DMYSQL_DATADIR=/Users/jianhaixu/secrect/opensource/mysql-server/debug/data
-DSYSCONFDIR=/Users/jianhaixu/secrect/opensource/mysql-server/debug
-DMYSQL_UNIX_ADDR=/Users/jianhaixu/secrect/opensource/mysql-server/debug/data/mysql.sock
-DWITH_DEBUG=1 -DFORCE_INSOURCE_BUILD=1
-DDOWNLOAD_BOOST=1
-DWITH_BOOST=/Users/jianhaixu/Downloads/boost_1_70_0
make -j 4
make install -j 4
bin/mysqld &amp;ndash;initialize-insecure &amp;ndash;user=root &amp;ndash;datadir=/Users/jianhaixu/secrect/opensource/mysql-server/debug/data
bin/mysqld &amp;ndash;defaults-file=/Users/jianhaixu/secrect/opensource/mysql-server/debug/etc/my.cnf</description>
    </item>
    
  </channel>
</rss>