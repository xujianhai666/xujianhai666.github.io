<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>zero.xu blog</title>
    <link>https://xujianhai.fun/</link>
    <description>Recent content on zero.xu blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 05 Apr 2020 09:42:10 +0800</lastBuildDate>
    
	<atom:link href="https://xujianhai.fun/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Proxy_sam</title>
      <link>https://xujianhai.fun/posts/proxy_sam/</link>
      <pubDate>Sun, 05 Apr 2020 09:42:10 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/proxy_sam/</guid>
      <description>背景 最近在研究service mesh相关的实现, 除了知名的 envoy-proxy(c++写的), go写的知名mesh就是 mosn, 在饿了么, 也实现了mesh的产品: samaritan
设计 整体设计 samaritan 本质上是一个proxy, 通过 unix domain socket 和应用进程交互. samaritan-proxy 的设计有以下几个重要模块:
 instance: 一个samaritan-proxy就是一个实例 controller: 负责配置信息的变更和处理, 配置变更会启动一个proc Proc: 服务名绑定的 流量处理和转发抽象, 每一个 procName 对应一个Proc. 比如 redis的实现 就是一个 Proc. Proc 独立监听 网络端口和网络包处理 admin: 运维管理接口, 比如 获取配置、stats统计、pprof. admin端口是重用的. config: 动态配置实现, 获取动态配置 放到 event channel, 订阅者监听 event channel 处理配置变更  需要注意的是, proc 的协议相关实现 需要实现注册到 controller#procs 的map中, 注册目前依赖 Bootstrap#StaticServices 的配置信息.
主流程 先关注主流程, 协议启动:
Controller#handleEvent -&amp;gt; handleSvcAdd -&amp;gt; #tryEnsureProc -&amp;gt; newProc(controller.</description>
    </item>
    
    <item>
      <title>Qmq_delay</title>
      <link>https://xujianhai.fun/posts/qmq_delay/</link>
      <pubDate>Fri, 03 Apr 2020 14:02:08 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/qmq_delay/</guid>
      <description>背景 最近在调研延迟消息的设计和研发, 其中, 目前开源并在线上大规模使用的主要是 去哪儿的qmq, 本文主要针对 qmq 中的延迟消息实现进行分析
问题 作为一款延迟消息服务, 需要解决一下问题:
 延迟消息的底层存储 延迟消息的投递方式 延迟消息怎么保证稳定的到期 延迟消息到期怎么投递 延迟消息是否可以取消 主从同步  设计 qmq 的延迟设计中, 所有的消息投递到 message log, message log 相当于 wal, 会有一个IterateOffsetManager 异步读取 message log 构建 schedule log 和 hash wheel, schedule log 是每个目标到期时间的文件, 默认每分钟一个文件, 时间间隔可以定制. hash wheel 是内存的多层时间轮, 所有后续的延迟消息 以及 到期的schedule log文件的消息 都会加载到内存中. 消息到期后, 会投递给 正常的消息服务的broker (投递会目标subject)
底层存储 qmq 本身设计了一套文件存储形式, 延迟功能基于这套存储进行了封装和实现, 除此之外, 延迟功能在内存中也维护了一份 时间轮的消息索引, 这里主要分析文件侧实现. 在延迟消息存储的设计中, 主要是以下模块:
  LogSegment&amp;amp;LogManager: qmq底层文件存储 和 文件目录管理(以及recover) 的实现, 延迟消息和普通消息基于这个做定制化.</description>
    </item>
    
    <item>
      <title>Mesh_file</title>
      <link>https://xujianhai.fun/posts/mesh_file/</link>
      <pubDate>Sat, 28 Mar 2020 23:36:12 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/mesh_file/</guid>
      <description>记录 service mesh 的一些相关资料:
 http://www.360doc.com/content/19/0907/06/46368139_859593650.shtml  </description>
    </item>
    
    <item>
      <title>Rocketmq_nomessage</title>
      <link>https://xujianhai.fun/posts/rocketmq_nomessage/</link>
      <pubDate>Thu, 26 Mar 2020 23:33:04 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/rocketmq_nomessage/</guid>
      <description>背景 最近在修rocketmq-golang-client的问题的时候, 发现在处理 PullNoNewMsg 的时候会导致 offset 被自动提交, 但是用户并没有设置自动ack, 并且也没有手动ack
注:
rocketmq 开源的版本并没有ack的概念
排查 于是, 通过日志打印调试, 发现是在 rocketmq-client-go 拉取消息处理 primitive.PullNoNewMsg 的状态的时候, 直接将 result.NextBeginOffset 替换为 request.nextOffset, 并且还 更新了本地offsetStore的offset 信息, 因为 rocektmq-client-go 是 周期性提交offset, 所以导致了 offset被ack 了
解决 在rocketmq-client-go的内部开发版本中, 直接将 offset 的本地存储更新给注释掉就可以了, 因为内部开发中, 是异步处理处理消息的, 并且offset的提交不需要满足递增的特性 (考虑到很多场景中可能存在 offset被移动到 更小的情况)
在开源的版本中, 对齐java的实现, 判断 processQueue是否有消息, 如果没有消息, 在更新本地offsetStore, 避免提交了 正在消费的消息
更多的理解 乘这次机会, 重新梳理了 rocketmq 在 pullMessage 的响应逻辑的处理. 根据客户端处理的逻辑, 区分如下 (不涉及到transaction)
1.NO_NEW_MSG
当broker返回 ResponseCode.PULL_NOT_FOUND 的时候, 客户端会转义成 PullStatus.NO_NEW_MSG, 会执行如下操作:</description>
    </item>
    
    <item>
      <title>Rocketmq_search</title>
      <link>https://xujianhai.fun/posts/rocketmq_search/</link>
      <pubDate>Wed, 25 Mar 2020 18:22:56 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/rocketmq_search/</guid>
      <description>背景 最近基于golang做了 消息查询的功能, 这里做一些记录
原理 rocketmq的消息查询, 支持两种模式: offsetMsgId 和 msgkey、uniqueKey, 我这里避免了 msgid 的命名, 因为在 rocketmq client的实现过程中, msgid 存在很大的差异.
基本概念 offsetMsgId
offsetMsgId 本质上是 rocketmq commitLog 生成的, 生成格式如下:
 public static String createMessageId(final ByteBuffer input, final ByteBuffer addr, final long offset) { input.flip(); int msgIDLength = addr.limit() == 8 ? 16 : 28; input.limit(msgIDLength); input.put(addr); input.putLong(offset); return UtilAll.bytes2string(input.array()); } 可以发现, offsetMsgId 是基于commitLog 所在的地址 + 消息的offset 组成, 保证了 唯一性. 因此通过offsetMsgId 可以借助这个特性.
msgkey
在消息发送的时候, 发送的消息是可以指定消息的key的, 需要注意的是, msgKey可以设置多个.</description>
    </item>
    
    <item>
      <title>Rocketmq_recover</title>
      <link>https://xujianhai.fun/posts/rocketmq_recover/</link>
      <pubDate>Tue, 24 Mar 2020 23:43:23 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/rocketmq_recover/</guid>
      <description>背景 最近要开发延迟消息, 这里记录下 recover相关的逻辑实现
原理 之前知道, rocketmq是所有的消息统一投递到 commitlog, 然后异步构建 consumer queue, 那么, 如果机器正常重启/异常宕机的情况下, 又是怎么恢复的呢?
前菜 rocketmq 使用了 checkpoint 文件记录了 physicMsgTimestamp logicsMsgTimestamp indexMsgTimestamp 三个字段, 分别表示 commitlog 的flush的时间点、comsumer queue的flush的时间点、index file 刷新的时间点. 也就是 已经落地磁盘的时间点. (通过fileChannel#force)
那么 这些时间点什么场景下会被更新, 什么时候checkpoint会flush呢?
 physicMsgTimestamp  首先, CommitLog 本身既有一个定时flush的任务, 根据flush方式的不同, 有两种实现: GroupCommitService 和 FlushRealTimeService(后面单独分析), 无论是同步还是异步, 每次flush之后都会设置 physicMsgTimestamp.
除此之外, 在 dledger模式中, slave构建 consumer queue的时候 也会设置 physicMsgTimestamp
logicsMsgTimestamp  在定时flush consumer queue 以及 追加consumer queue消息的时候, 都会更新. (因此, logicsMsgTimestamp 并不是 consumer queue flush的时间)</description>
    </item>
    
    <item>
      <title>Rocketmq_flow_control</title>
      <link>https://xujianhai.fun/posts/rocketmq_flow_control/</link>
      <pubDate>Mon, 23 Mar 2020 22:31:59 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/rocketmq_flow_control/</guid>
      <description>背景 rocketmq推广过程中, 偶尔会遇到 [TIMEOUT_CLEAN_QUEUE]broker busy, start flow control for a while, period in queue: 201ms, size of queue: 5389 类似的报错, 导致上游业务失败率报警以及错误日志飙升. 在相应的监控上, rocketmq 的发送qps也是非常高.
原因 其实这个行为是 rocektmq broker 的自我保护机制, 那么什么时候会触发呢? 这个主要是在 store 进行put 消息的时候会触发. 之前讲过, 在 rocketmq 的处理机制中, netty 将读取到的消息 会封装成 RequestTask 对象提交到 executorService 的队列中, 然后等待 executorService 调度执行. 那么, 这里存在两种情况:
  queue已经被写满了, 无法再提交新的任务, 那么会触发 RejectedExecutionException, 这个时候, rocketmq broker 会返回 RemotingSysResponseCode.SYSTEM_BUSY, 提示信息是: [OVERLOAD]. 参考: NettyRemotingAbstract#processRequestCommand
  调度延迟的问题. 我在 11:05 提交了一个写入请求, 但是因为 写入流程耗时 增加, 导致我的请求到 11:06 才被处理, 对于实时在线业务而言, 这条消息其实早就超时了, 这种情况, rocketmq 有两套机制:</description>
    </item>
    
    <item>
      <title>Rocketmq_msgid</title>
      <link>https://xujianhai.fun/posts/rocketmq_msgid/</link>
      <pubDate>Tue, 17 Mar 2020 18:18:05 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/rocketmq_msgid/</guid>
      <description>最近利用 msgId 进行一些延迟实现, 结果发现, msgId 在 producer 和 consumer 两侧是不一致的.
复现 我用producer发送一条消息如下:
SendResult [sendStatus=SEND_OK, msgId=0AFE2AEF000018B4AAC2562A9AC70000, offsetMsgId=0AE1578800002A9F0000000C6C988CC2, messageQueue=MessageQueue [topic=test_create_topic, brokerName=sandbox_boe4, queueId=0], queueOffset=0] 需要注意的是, msgId 和 offsetMsgId 是不一样的. 在consumer侧, 我接受到的消息如下:
Receive New Messages: [MessageExt [queueId=0, storeSize=197, queueOffset=0, sysFlag=0, bornTimestamp=1584437632711, bornHost=/10.254.42.239:49872, storeTimestamp=1584437632868, storeHost=/10.225.87.136:10911, msgId=0AE1578800002A9F0000000C6C988CC2, commitLogOffset=53361544386, bodyCRC=198614610, reconsumeTimes=0, preparedTransactionOffset=0, toString()=Message{topic=&#39;test_create_topic&#39;, flag=0, properties={MIN_OFFSET=0, MAX_OFFSET=1, KEYS=OrderID188, CONSUME_START_TIME=1584437674686, UNIQ_KEY=0AFE2AEF000018B4AAC2562A9AC70000, WAIT=true, TAGS=TagA}, body=[72, 101, 108, 108, 111, 32, 119, 111, 114, 108, 100], transactionId=&#39;null&#39;}]] consumer 收到的 msg的 msgId 和 producer的 msgId 是不一样的, 但是, producer侧的msgId 和 consumer侧的 UNIQUE_KEY 的值是一样的, producer 的 offsetMsgId 和 consumer侧的 msgId 是一致的.</description>
    </item>
    
    <item>
      <title>Kip_broker</title>
      <link>https://xujianhai.fun/posts/kip_broker/</link>
      <pubDate>Mon, 09 Mar 2020 23:13:41 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/kip_broker/</guid>
      <description>这里主要记录kafka broker 的相关proposal
 broker 增加配置: fetch.max.bytes, 避免部分consumer影响其他consumer.
proposal</description>
    </item>
    
    <item>
      <title>Rocketmq_allocate</title>
      <link>https://xujianhai.fun/posts/rocketmq_allocate/</link>
      <pubDate>Sun, 08 Mar 2020 20:04:52 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/rocketmq_allocate/</guid>
      <description>最近一年中, 经常有用户不同的服务用一个group分别订阅不同的topic, 导致部分partition不消费
 场景 业务反馈的时候, 通常是 监控上部分partition lag 增长, 并且queue的消费qps是0.
通过使用 mqadmin consumerProgress 查看offset 提交的时候, 发现这个group提交了多个topic, 并且每次结果不一样
-&amp;gt; % mqadmin consumerProgress -g groupA -n $addr -s true RocketMQLog:WARN No appenders could be found for logger (io.netty.util.internal.PlatformDependent0). RocketMQLog:WARN Please initialize the logger system properly. #Topic #Broker Name #QID #Broker Offset #Consumer Offset #Client IP #Diff #LastTime %RETRY%groupA broker1 0 0 0 ip1 0 N/A topicA broker1 0 2180901 2180901 ip1 0 2020-03-08 20:10:04 topicA broker1 1 2000000 0 ip1 200000 2020-03-08 00:10:04 -&amp;gt; % mqadmin consumerProgress -g groupA -n $addr -s true RocketMQLog:WARN No appenders could be found for logger (io.</description>
    </item>
    
  </channel>
</rss>