<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>copyset on zero.xu blog</title>
    <link>https://xujianhai.fun/tags/copyset/</link>
    <description>Recent content in copyset on zero.xu blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 15 Jan 2021 21:02:51 +0800</lastBuildDate>
    
	<atom:link href="https://xujianhai.fun/tags/copyset/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Essay_copyset</title>
      <link>https://xujianhai.fun/posts/essay_copyset/</link>
      <pubDate>Fri, 15 Jan 2021 21:02:51 +0800</pubDate>
      
      <guid>https://xujianhai.fun/posts/essay_copyset/</guid>
      <description>前言 这个论文是从 网易的curve项目了解到的(块存储项目), 浏览了整个论文之后, 发现论文主要是为了解决 大量数据丢失 &amp;amp; 高频数据丢失 折中的处理方案, 通过对比大量数据, 得出 低频大尺寸数据丢失 优先的结论, copyset 的设计将 数据丢失降低, 通过应用 copyset, 将 RAM Cloud 5000节点的 数据丢失率从 99.99%-&amp;gt;0.15%, facebook hdfs 数据丢失率 从 22.8%-&amp;gt; 0.78%.
论文参考: 1
基本概念 关于数据丢失: 大规模集群中, 经常会遭受 断电 等数据中心失败场景, 比如断电, 即使电力恢复, 也有 0.5%-1.0%的 节点无法恢复, 很有可能一个chunk的所有副本都不可用, 从而导致数据丢失
关于数据恢复: 数据修复成本 并不是和 丢失的数据成比例, 而是定位 丢失chunk 所在的完整数据.
tradeoff(frenquency vs lost data size): 假设每年丢失的不可用数据量是固定的, 那么, 相比于 更多丢失次数 * 每次更少的数据丢失, 我们倾向于 更少的丢失次数 * 每次更多的数据丢失.
 对比  random replication: chunk 随机分布在 R 个副本上</description>
    </item>
    
  </channel>
</rss>